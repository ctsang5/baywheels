{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25486399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "from shapely.geometry import LineString\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import numpy as np\n",
    "from linearmodels import PanelOLS\n",
    "\n",
    "BAYWHEELS = Path(\"../data/processed/baywheels_sf.csv\")\n",
    "RIDERSHIP = Path(\"../data/raw/RidershipbyRouteTableDownload.csv\") \n",
    "\n",
    "GTFS_ROUTES = Path(\"../data/raw/routes.txt\")  \n",
    "GTFS_TRIPS = Path(\"../data/raw/trips.txt\")\n",
    "GTFS_STOPS = Path(\"../data/raw/stops.txt\") \n",
    "\n",
    "GTFS_STOP_TIMES = Path(\"../data/raw/stop_times.txt\")      \n",
    "GTFS_SHAPES = Path(\"../data/raw/shapes.txt\")       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f96e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "baywheels_sf = pd.read_csv(BAYWHEELS, engine = 'pyarrow')        \n",
    "muni = pd.read_csv(RIDERSHIP, engine = 'pyarrow')\n",
    "\n",
    "routes = pd.read_csv(GTFS_ROUTES, engine = 'pyarrow')\n",
    "trips = pd.read_csv(GTFS_TRIPS, engine = 'pyarrow')\n",
    "stops = pd.read_csv(GTFS_STOPS, engine = 'pyarrow')\n",
    "stop_times = pd.read_csv(GTFS_STOP_TIMES, engine = 'pyarrow')\n",
    "shapes = pd.read_csv(GTFS_SHAPES, engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6158cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "baywheels_sf = baywheels_sf[baywheels_sf['end_station_id'] != 'SF-Y7'].copy() \n",
    "baywheels_sf = baywheels_sf[baywheels_sf['started_at'] > '2019-06-01'].copy()\n",
    "\n",
    "bikeshare_stations = baywheels_sf.sort_values('ended_at').drop_duplicates(subset = ['end_station_id'], keep = 'first').copy()\n",
    "bikeshare_stations = bikeshare_stations[['end_station_id', 'end_lat', 'end_lng', 'ended_at']].rename(columns = {'ended_at': 'first_appeared_at'})\n",
    "bikeshare_stations['first_appeared_at'] = pd.to_datetime(bikeshare_stations['first_appeared_at']).dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2f3d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "muni['Month'] = pd.to_datetime(muni['Month'], format = '%B %Y').dt.normalize()\n",
    "\n",
    "muni.dropna(subset = ['Average Daily Boardings'], inplace = True)\n",
    "muni['Average Daily Boardings'] = muni['Average Daily Boardings'].str.replace(',', '').astype('int64')\n",
    "\n",
    "BUS_SERIVCE_CATEGORIES = ['Frequent Local', 'Grid', 'Rapid Bus', 'Connector']\n",
    "muni = muni[muni['Service Category'].isin(BUS_SERIVCE_CATEGORIES)].copy()\n",
    "muni['Route'] = muni['Route'].str.upper()\n",
    "muni = muni[muni['Service Day of the Week'] == 'Weekday'][['Month', 'Route', 'Average Daily Boardings']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aab0f50",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_routes = routes[routes['route_type'] == 3].copy()\n",
    "bus_trips = trips[trips['route_id'].isin(bus_routes['route_id'])].copy()\n",
    "bus_stop_times = stop_times[stop_times['trip_id'].isin(bus_trips['trip_id'])].copy()\n",
    "\n",
    "bus_stop_times = bus_stop_times.merge(stops[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']], on = 'stop_id', how = 'left')\n",
    "bus_trips = bus_trips.merge(bus_routes[['route_id', 'route_short_name', 'route_long_name']], on = 'route_id', how = 'left')\n",
    "\n",
    "bus_route_stops = bus_stop_times.merge(bus_trips[['trip_id', 'route_id', 'route_short_name', 'route_long_name', 'direction_id', 'trip_headsign']])\n",
    "\n",
    "route_stops = bus_route_stops.sort_values(['route_id', 'direction_id', 'stop_sequence']).drop_duplicates(['route_id', 'direction_id', 'stop_id'])\n",
    "\n",
    "keep_route_stop_columns = ['stop_id', 'direction_id', 'stop_sequence', 'stop_name', 'route_short_name', 'route_long_name', 'stop_lat', 'stop_lon']\n",
    "route_stops = route_stops[keep_route_stop_columns]\n",
    "\n",
    "route_stops = route_stops[route_stops['direction_id'] == 1].copy()              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c673f708",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = shapes.sort_values(['shape_id', 'shape_pt_sequence'])\n",
    "\n",
    "bus_shapes = shapes.groupby('shape_id')[['shape_pt_lon', 'shape_pt_lat']].apply(lambda df: LineString(zip(df['shape_pt_lon'], df['shape_pt_lat']))).reset_index(name = 'geometry')\n",
    "bus_shapes_gdf = gpd.GeoDataFrame(bus_shapes, geometry = 'geometry', crs = 'EPSG:4326')\n",
    "\n",
    "bus_shape_routes = bus_shapes_gdf.merge(bus_trips.drop_duplicates('shape_id'), on = 'shape_id', how = 'left')\n",
    "bus_shape_routes = bus_shape_routes[bus_shape_routes['direction_id'] == 1.0]\n",
    "bus_shape_routes = bus_shape_routes[bus_shape_routes['route_id'].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947f9137",
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_route_number_dictionary = {\n",
    "    '21': '6'\n",
    "}\n",
    "\n",
    "muni_route_long_name_dictionary = {\n",
    "    'HAYES': 'HAYES/PARNASSUS',\n",
    "    'HAIGHT/PARNASSUS': 'HAYES/PARNASSUS'\n",
    "}\n",
    "\n",
    "muni_drop_suspended_routes_list = ['JACKSON', 'TOWNSEND', 'VAN NESS']      \n",
    "\n",
    "standardize_route_stops_long_name_dictionary = {\n",
    "    'HAYES-PARNASSUS': 'HAYES/PARNASSUS',       \n",
    "    'HAIGHT-NORIEGA': 'HAIGHT/NORIEGA',\n",
    "    'FOLSOM-PACIFIC': 'FOLSOM/PACIFIC',\n",
    "    'ASHBURY-18TH ST': 'ASHBURY/18TH',\n",
    "    'UNION-STOCKTON': 'UNION/STOCKTON',\n",
    "    'VAN NESS-MISSION': 'VAN NESS/MISSION',\n",
    "    'QUINTARA-24TH STREET': 'QUINTARA/24TH STREET',\n",
    "\n",
    "}\n",
    "\n",
    "route_stops_drop_routes_list = ['BAYVIEW HUNTERS POINT EXPRESS','CALIFORNIA EXPRESS','MARINA EXPRESS','BART EARLY BIRD','BAYSHORE A EXPRESS',\n",
    "                                'BAYSHORE B EXPRESS', 'SAN BRUNO OWL','3RD-19TH AVE OWL','INGLESIDE BUS','OWL TARAVAL',\n",
    "                                'JUDAH BUS','OWL JUDAH','THIRD BUS']\n",
    "\n",
    "\n",
    "muni[['route_number', 'route_long_name']] = muni['Route'].str.split(' ', n = 1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2e4c59",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_stops['route_long_name'] = route_stops['route_long_name'].replace(standardize_route_stops_long_name_dictionary)\n",
    "muni['route_long_name'] = muni['route_long_name'].replace(muni_route_long_name_dictionary)\n",
    "\n",
    "muni['route_number'] = muni['route_number'].replace(muni_route_number_dictionary)\n",
    "\n",
    "muni = muni[~muni['route_long_name'].isin(muni_drop_suspended_routes_list)]\n",
    "route_stops = route_stops[~route_stops['route_long_name'].isin(route_stops_drop_routes_list)]\n",
    "\n",
    "muni = muni[['Month', 'Average Daily Boardings', 'route_number', 'route_long_name']]\n",
    "route_stops = route_stops[['stop_id', 'stop_name', 'stop_lat', 'stop_lon', 'route_long_name']] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0010f07b",
   "metadata": {},
   "source": [
    "# Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9643a97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_gdf = gpd.GeoDataFrame(route_stops, geometry = gpd.points_from_xy(route_stops['stop_lon'], route_stops['stop_lat'], crs = 'EPSG:4326').to_crs(epsg = 3857))\n",
    "stations_gdf = gpd.GeoDataFrame(bikeshare_stations, geometry = gpd.points_from_xy(bikeshare_stations['end_lng'], bikeshare_stations['end_lat']), crs = 'EPSG:4326').to_crs(epsg = 3857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb8435f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN RESULT AND SENSITIVTY TESTS\n",
    "buffer_sizes = [200, 300, 400, 500]\n",
    "regression_results_dictionary = {}\n",
    "\n",
    "route_month = muni[['route_long_name', 'Month']].drop_duplicates()\n",
    "\n",
    "for size in buffer_sizes:\n",
    "    stops_buffered = stops_gdf.copy()\n",
    "    stops_buffered['geometry'] = stops_buffered.geometry.buffer(size)\n",
    "\n",
    "    route_stop_station = gpd.sjoin(stations_gdf, stops_buffered, predicate = 'within', how = 'inner')\n",
    "    route_station_pairs = route_stop_station[['route_long_name', 'end_station_id', 'first_appeared_at']].drop_duplicates()\n",
    "\n",
    "    route_month_station = route_month.merge(route_station_pairs, on = 'route_long_name', how = 'left')\n",
    "\n",
    "    mask_active = route_month_station['first_appeared_at'] <= route_month_station['Month']\n",
    "    route_month_station = route_month_station[mask_active]\n",
    "\n",
    "    route_month_station_counts = route_month_station.groupby(['route_long_name', 'Month'])['end_station_id'].nunique().reset_index(name = 'unique_stations_in_buffer')\n",
    "\n",
    "    muni_with_station_counts = muni.merge(route_month_station_counts, on = ['route_long_name', 'Month'], how = 'left').fillna({'unique_stations_in_buffer': 0})\n",
    "\n",
    "    muni_with_station_counts['treated'] = (muni_with_station_counts['unique_stations_in_buffer'] > 0).astype(int)\n",
    "\n",
    "    df = muni_with_station_counts.copy()\n",
    "    panel = df.set_index(['route_number', 'Month'])\n",
    "    \n",
    "    panel['log_boardings'] = np.log(panel['Average Daily Boardings'])\n",
    "\n",
    "    model = PanelOLS(dependent = panel['log_boardings'], exog = panel[['unique_stations_in_buffer']], entity_effects = True, time_effects = True)\n",
    "    result = model.fit(cov_type = 'clustered', cluster_entity = True)\n",
    "\n",
    "    regression_results_dictionary[size] = result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf1aa85",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_study_results_list = []\n",
    "\n",
    "for size in buffer_sizes:\n",
    "    stops_buffered = stops_gdf.copy()\n",
    "    stops_buffered['geometry'] = stops_buffered.geometry.buffer(size)\n",
    "    route_stop_station = gpd.sjoin(stations_gdf, stops_buffered, predicate = 'within', how = 'inner')\n",
    "    route_station_pairs = route_stop_station[['route_long_name', 'end_station_id', 'first_appeared_at']].drop_duplicates()\n",
    "    route_month_station = route_month.merge(route_station_pairs, on = 'route_long_name', how = 'left')\n",
    "    mask_active = route_month_station['first_appeared_at'] <= route_month_station['Month']\n",
    "    route_month_station = route_month_station[mask_active]\n",
    "    route_month_station_counts = route_month_station.groupby(['route_long_name', 'Month'])['end_station_id'].nunique().reset_index(name = 'unique_stations_in_buffer')\n",
    "\n",
    "    muni_with_station_counts = muni.merge(route_month_station_counts, on = ['route_long_name', 'Month'], how = 'left').fillna({'unique_stations_in_buffer': 0})\n",
    "\n",
    "\n",
    "    df = muni_with_station_counts.copy()\n",
    "    df['treated'] = (df['unique_stations_in_buffer'] > 0).astype(int)\n",
    "\n",
    "    treatment_starts = df[df['treated'] == 1].groupby('route_long_name')['Month'].min().reset_index()\n",
    "    treatment_starts.rename(columns = {'Month': 'treatment_start_date'}, inplace = True)\n",
    "    df = df.merge(treatment_starts, on = 'route_long_name', how = 'left')\n",
    "\n",
    "    df['relative_month'] = df['Month'].dt.to_period('M').astype('int64') - df['treatment_start_date'].dt.to_period('M').astype('int64')\n",
    "\n",
    "    WINDOW_LOWER = -5\n",
    "    WINDOW_UPPER = 4\n",
    "    df['event_time'] = df['relative_month'].clip(lower = WINDOW_LOWER, upper = WINDOW_UPPER)\n",
    "\n",
    "    dummies = pd.get_dummies(df['event_time'], prefix = 'event')\n",
    "    df = pd.concat([df, dummies], axis = 1)\n",
    "\n",
    "    event_cols = [c for c in dummies.columns if c != 'event_-1' and 'nan' not in c]\n",
    "\n",
    "    panel = df.set_index(['route_number', 'Month'])\n",
    "    panel['log_boardings'] = np.log(panel['Average Daily Boardings'])\n",
    "\n",
    "    model = PanelOLS(dependent = panel['log_boardings'], exog = panel[event_cols], entity_effects = True, time_effects = True)\n",
    "    result = model.fit(cov_type = 'clustered', cluster_entity = True)\n",
    "   \n",
    "    event_study_results_list.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5020476",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, (size, result) in enumerate(zip(buffer_sizes, event_study_results_list), 1):\n",
    "\n",
    "    coefs = result.params\n",
    "\n",
    "    plot_data = pd.DataFrame({\n",
    "        'time': [int(c.replace('event_', '')) for c in coefs.index if 'event_' in c],\n",
    "        'coef': coefs.values\n",
    "    })\n",
    "\n",
    "    ref_row = pd.DataFrame({'time': [-1], 'coef': [0], 'lower': [0], 'upper': [0]})\n",
    "    plot_data = pd.concat([plot_data, ref_row]).sort_values('time')\n",
    "\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "  \n",
    "    plt.plot(plot_data['time'], plot_data['coef'], color = 'green', marker = 'o', linewidth = 2)\n",
    "  \n",
    "    plt.axhline(0, color = 'black', linestyle = '-', linewidth = 0.8)\n",
    "    plt.axvline(-0.5, color = 'red', linestyle = '--', linewidth = 1)\n",
    "    \n",
    "    plt.title(f\"Figure {i}: {size} Meter Buffer\")\n",
    "    \n",
    "    plt.xlabel(\"months relative to station opening\")\n",
    "    plt.ylabel(\"coefficients\")\n",
    "    plt.grid(True, linestyle = ':', alpha = 0.6)\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f2db11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HOW DID I DEFINE TREATMENT? (GIF)\n",
    "bus_df = bus_shape_routes\n",
    "bike_df = bikeshare_stations\n",
    "\n",
    "monthly_dates = pd.date_range(start = bike_df['first_appeared_at'].min(), end = bike_df['first_appeared_at'].max(), freq = 'ME')\n",
    "\n",
    "bus_gdf = gpd.GeoDataFrame(bus_df, geometry = 'geometry', crs = 'EPSG: 4326')\n",
    "bus_gdf_3857 = bus_gdf.to_crs(epsg = 3857)\n",
    "\n",
    "bike_gdf = gpd.GeoDataFrame(bike_df, geometry = gpd.points_from_xy(bike_df.end_lng, bike_df.end_lat), crs = 'EPSG:4326')\n",
    "bike_gdf_3857 = bike_gdf.to_crs(epsg = 3857)\n",
    "bike_gdf_3857['x_3857'] = bike_gdf_3857.geometry.x\n",
    "bike_gdf_3857['y_3857'] = bike_gdf_3857.geometry.y\n",
    "\n",
    "target_route_name = '18'\n",
    "target_route = bus_gdf_3857[bus_gdf_3857['route_short_name'] == target_route_name]\n",
    "\n",
    "treatment_zone = target_route.buffer(400)\n",
    "treatment_polygon = treatment_zone.geometry.iloc[0]\n",
    "\n",
    "minx, miny, maxx, maxy = treatment_zone.total_bounds\n",
    "buffer_margin = 1000\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (7,7))\n",
    "ax.set_xlim(minx - buffer_margin, maxx + buffer_margin)\n",
    "ax.set_ylim(miny - buffer_margin, maxy + buffer_margin)\n",
    "ax.axis('off')\n",
    "fig.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1)\n",
    "\n",
    "treatment_zone.plot(ax = ax, color = 'orange', alpha = 0.1, edgecolor = 'orange', linestyle = '--', linewidth = 1)\n",
    "target_route.plot(ax = ax, color = 'blue', linewidth = 3, alpha = 0.8)\n",
    "ctx.add_basemap(ax, source = ctx.providers.CartoDB.Positron)\n",
    "\n",
    "scat_outside = ax.scatter([], [], c = 'red', s=50, alpha=0.7, edgecolors='white', linewidth = 0.5, zorder = 5)\n",
    "scat_inside = ax.scatter([], [], c = 'green', s=50, alpha=1.0, edgecolors='white', linewidth = 0.5, zorder = 6)\n",
    "\n",
    "date_text = ax.text(0.02, 0.95, '', transform = ax.transAxes, fontsize = 12, bbox = dict(facecolor = 'white', alpha = 0.9, boxstyle = 'round'))\n",
    "\n",
    "def update(frame_date):\n",
    "    current_stations = bike_gdf_3857[bike_gdf_3857['first_appeared_at'] <= frame_date]\n",
    "    \n",
    "    is_inside_mask = current_stations.geometry.within(treatment_polygon)\n",
    "\n",
    "    stations_in = current_stations[is_inside_mask]\n",
    "    stations_out = current_stations[~is_inside_mask]\n",
    "\n",
    "    if not stations_in.empty:\n",
    "        scat_inside.set_offsets(np.c_[stations_in['x_3857'], stations_in['y_3857']])\n",
    "    else:\n",
    "        scat_inside.set_offsets(np.empty((0, 2)))\n",
    "\n",
    "    if not stations_out.empty:\n",
    "        scat_outside.set_offsets(np.c_[stations_out['x_3857'], stations_out['y_3857']])\n",
    "    else:\n",
    "        scat_outside.set_offsets(np.empty((0, 2)))\n",
    "\n",
    "    date_text.set_text(frame_date.strftime('%B %Y'))\n",
    "\n",
    "    return scat_inside, scat_outside , date_text\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames = monthly_dates, interval = 150, blit = True)\n",
    "output_file = 'method_treatment_definition.gif'\n",
    "ani.save(output_file, writer = 'pillow', fps = 3, dpi = 100)\n",
    "plt.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "19a8ef71-69bc-4f86-8d7c-12be944a1ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "import geopandas as gpd\n",
    "import contextily as ctx\n",
    "from shapely.geometry import LineString\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "\n",
    "import numpy as np\n",
    "from linearmodels import PanelOLS\n",
    "\n",
    "BAYWHEELS = Path("./DATA")  # BAYWHEELS DATA GOES HERE \n",
    "RIDERSHIP = Path("./DATA")  # SFMTA MONTHLY AVERAGE WEEKDAY RIDERSHIP DATA GOES HERE \n",
    "\n",
    "GTFS_ROUTES = Path("./DATA")   # SFMTA ROUTES DATA, \n",
    "GTFS_TRIPS = Path("./DATA")    # SFMTA TRIPS DATA, \n",
    "GTFS_STOPS = Path("./DATA")    # SFMTA STOPS DATA, \n",
    "\n",
    "GTFS_STOP_TIMES = Path("./DATA") # SFMTA STOP TIMES DATA, \n",
    "GTFS_SHAPES = Path("./DATA")     # SFMTA SHAPES DATA \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd665cc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "baywheels_sf = pd.read_csv(BAYWHEELS, engine = 'pyarrow')         # REMEMBER: A STATION ID CAN HAVE MULTIPLE STATION NAMES BECAUSE THESE STATIONS ARE VERY CLOSE TOGETHER SO I ASSIGNED THEM ALL THE SAME STATION ID  \n",
    "muni = pd.read_csv(RIDERSHIP, engine = 'pyarrow')\n",
    "\n",
    "routes = pd.read_csv(GTFS_ROUTES, engine = 'pyarrow')\n",
    "trips = pd.read_csv(GTFS_TRIPS, engine = 'pyarrow')\n",
    "stops = pd.read_csv(GTFS_STOPS, engine = 'pyarrow')\n",
    "stop_times = pd.read_csv(GTFS_STOP_TIMES, engine = 'pyarrow')\n",
    "shapes = pd.read_csv(GTFS_SHAPES, engine = 'pyarrow')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7706863",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IF A STATION ID HAS MULTIPLE STATION NAMES IT SHOULDN'T MATTER WHICH STATION NAME'S COORDINATES IS CHOSEN BECAUSE I SET THEM TO BE ALL THE SAME \n",
    "baywheels_sf = baywheels_sf[baywheels_sf['end_station_id'] != 'SF-Y7'].copy() \n",
    "baywheels_sf = baywheels_sf[baywheels_sf['started_at'] > '2019-06-01'].copy() # Lyft Acquires Fordgo BIkes and rebrands as Bay Wheels\n",
    "\n",
    "bikeshare_stations = baywheels_sf.sort_values('ended_at').drop_duplicates(subset = ['end_station_id'], keep = 'first').copy()\n",
    "bikeshare_stations = bikeshare_stations[['end_station_id', 'end_lat', 'end_lng', 'ended_at']].rename(columns = {'ended_at': 'first_appeared_at'})\n",
    "bikeshare_stations['first_appeared_at'] = pd.to_datetime(bikeshare_stations['first_appeared_at']).dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56f7bfe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "muni['Month'] = pd.to_datetime(muni['Month'], format = '%B %Y').dt.normalize()\n",
    "\n",
    "muni.dropna(subset = ['Average Daily Boardings'], inplace = True)\n",
    "muni['Average Daily Boardings'] = muni['Average Daily Boardings'].str.replace(',', '').astype('int64')\n",
    "\n",
    "BUS_SERIVCE_CATEGORIES = ['Frequent Local', 'Grid', 'Rapid Bus', 'Connector']\n",
    "muni = muni[muni['Service Category'].isin(BUS_SERIVCE_CATEGORIES)].copy()\n",
    "muni['Route'] = muni['Route'].str.upper()\n",
    "muni = muni[muni['Service Day of the Week'] == 'Weekday'][['Month', 'Route', 'Average Daily Boardings']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a1ef6be",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_routes = routes[routes['route_type'] == 3].copy()\n",
    "bus_trips = trips[trips['route_id'].isin(bus_routes['route_id'])].copy()\n",
    "bus_stop_times = stop_times[stop_times['trip_id'].isin(bus_trips['trip_id'])].copy()\n",
    "\n",
    "bus_stop_times = bus_stop_times.merge(stops[['stop_id', 'stop_name', 'stop_lat', 'stop_lon']], on = 'stop_id', how = 'left')\n",
    "bus_trips = bus_trips.merge(bus_routes[['route_id', 'route_short_name', 'route_long_name']], on = 'route_id', how = 'left')\n",
    "\n",
    "bus_route_stops = bus_stop_times.merge(bus_trips[['trip_id', 'route_id', 'route_short_name', 'route_long_name', 'direction_id', 'trip_headsign']])\n",
    "\n",
    "route_stops = bus_route_stops.sort_values(['route_id', 'direction_id', 'stop_sequence']).drop_duplicates(['route_id', 'direction_id', 'stop_id'])\n",
    "\n",
    "keep_route_stop_columns = ['stop_id', 'direction_id', 'stop_sequence', 'stop_name', 'route_short_name', 'route_long_name', 'stop_lat', 'stop_lon']\n",
    "route_stops = route_stops[keep_route_stop_columns]\n",
    "\n",
    "route_stops = route_stops[route_stops['direction_id'] == 1].copy()              # PICK A DIRECTION: I PICKED INBOUND"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c56a7070",
   "metadata": {},
   "outputs": [],
   "source": [
    "shapes = shapes.sort_values(['shape_id', 'shape_pt_sequence'])\n",
    "\n",
    "bus_shapes = shapes.groupby('shape_id')[['shape_pt_lon', 'shape_pt_lat']].apply(lambda df: LineString(zip(df['shape_pt_lon'], df['shape_pt_lat']))).reset_index(name = 'geometry')\n",
    "bus_shapes_gdf = gpd.GeoDataFrame(bus_shapes, geometry = 'geometry', crs = 'EPSG:4326')\n",
    "\n",
    "bus_shape_routes = bus_shapes_gdf.merge(bus_trips.drop_duplicates('shape_id'), on = 'shape_id', how = 'left')\n",
    "bus_shape_routes = bus_shape_routes[bus_shape_routes['direction_id'] == 1.0]\n",
    "bus_shape_routes = bus_shape_routes[bus_shape_routes['route_id'].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed023666",
   "metadata": {},
   "outputs": [],
   "source": [
    "bus_df = bus_shape_routes\n",
    "bike_df = bikeshare_stations\n",
    "\n",
    "monthly_dates = pd.date_range(start = bike_df['first_appeared_at'].min(), end = bike_df['first_appeared_at'].max(), freq = 'ME')\n",
    "\n",
    "bus_gdf = gpd.GeoDataFrame(bus_df, geometry = 'geometry', crs = 'EPSG: 4326')\n",
    "bus_gdf_3857 = bus_gdf.to_crs(epsg = 3857)\n",
    "\n",
    "bike_gdf = gpd.GeoDataFrame(bike_df, geometry = gpd.points_from_xy(bike_df.end_lng, bike_df.end_lat), crs = 'EPSG:4326')\n",
    "bike_gdf_3857 = bike_gdf.to_crs(epsg = 3857)\n",
    "bike_gdf_3857['x_3857'] = bike_gdf_3857.geometry.x\n",
    "bike_gdf_3857['y_3857'] = bike_gdf_3857.geometry.y\n",
    "\n",
    "target_route_name = '18'\n",
    "target_route = bus_gdf_3857[bus_gdf_3857['route_short_name'] == target_route_name]\n",
    "\n",
    "treatment_zone = target_route.buffer(400)\n",
    "treatment_polygon = treatment_zone.geometry.iloc[0]\n",
    "\n",
    "minx, miny, maxx, maxy = treatment_zone.total_bounds\n",
    "buffer_margin = 1000\n",
    "\n",
    "fig, ax = plt.subplots(figsize = (12,12))\n",
    "ax.set_xlim(minx - buffer_margin, maxx + buffer_margin)\n",
    "ax.set_ylim(miny - buffer_margin, maxy + buffer_margin)\n",
    "ax.axis('off')\n",
    "fig.subplots_adjust(left = 0, bottom = 0, right = 1, top = 1)\n",
    "\n",
    "treatment_zone.plot(ax = ax, color = 'orange', alpha = 0.1, edgecolor = 'orange', linestyle = '--', linewidth = 1)\n",
    "target_route.plot(ax = ax, color = 'blue', linewidth = 3, alpha = 0.8)\n",
    "ctx.add_basemap(ax, source = ctx.providers.CartoDB.Positron)\n",
    "\n",
    "scat_outside = ax.scatter([], [], c = 'red', s=50, alpha=0.7, edgecolors='white', linewidth = 0.5, zorder = 5)\n",
    "scat_inside = ax.scatter([], [], c = 'green', s=50, alpha=1.0, edgecolors='white', linewidth = 0.5, zorder = 6)\n",
    "\n",
    "date_text = ax.text(0.02, 0.95, '', transform = ax.transAxes, fontsize = 12, bbox = dict(facecolor = 'white', alpha = 0.9, boxstyle = 'round'))\n",
    "\n",
    "def update(frame_date):\n",
    "    current_stations = bike_gdf_3857[bike_gdf_3857['first_appeared_at'] <= frame_date]\n",
    "    \n",
    "    is_inside_mask = current_stations.geometry.within(treatment_polygon)\n",
    "\n",
    "    stations_in = current_stations[is_inside_mask]\n",
    "    stations_out = current_stations[~is_inside_mask]\n",
    "\n",
    "    if not stations_in.empty:\n",
    "        scat_inside.set_offsets(np.c_[stations_in['x_3857'], stations_in['y_3857']])\n",
    "    else:\n",
    "        scat_inside.set_offsets(np.empty((0, 2)))\n",
    "\n",
    "    if not stations_out.empty:\n",
    "        scat_outside.set_offsets(np.c_[stations_out['x_3857'], stations_out['y_3857']])\n",
    "    else:\n",
    "        scat_outside.set_offsets(np.empty((0, 2)))\n",
    "\n",
    "    date_text.set_text(frame_date.strftime('%B %Y'))\n",
    "\n",
    "    return scat_inside, scat_outside , date_text\n",
    "\n",
    "\n",
    "ani = animation.FuncAnimation(fig, update, frames = monthly_dates, interval = 150, blit = True)\n",
    "output_file = 'method_treatment_definition.gif'\n",
    "ani.save(output_file, writer = 'pillow', fps = 3, dpi = 100)\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "334e59a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "muni_route_number_dictionary = {\n",
    "    '21': '6'\n",
    "}\n",
    "\n",
    "muni_route_long_name_dictionary = {\n",
    "    'HAYES': 'HAYES/PARNASSUS',\n",
    "    'HAIGHT/PARNASSUS': 'HAYES/PARNASSUS'\n",
    "}\n",
    "\n",
    "muni_drop_suspended_routes_list = ['JACKSON', 'TOWNSEND', 'VAN NESS']       # SUSPENDED\n",
    "\n",
    "standardize_route_stops_long_name_dictionary = {\n",
    "    'HAYES-PARNASSUS': 'HAYES/PARNASSUS',       # THE 6 HAYES-PERNASSUS REPLACED 21 HAYES AND 6 HAIGHT/PARNASSUS\n",
    "    'HAIGHT-NORIEGA': 'HAIGHT/NORIEGA',\n",
    "    'FOLSOM-PACIFIC': 'FOLSOM/PACIFIC',\n",
    "    'ASHBURY-18TH ST': 'ASHBURY/18TH',\n",
    "    'UNION-STOCKTON': 'UNION/STOCKTON',\n",
    "    'VAN NESS-MISSION': 'VAN NESS/MISSION',\n",
    "    'QUINTARA-24TH STREET': 'QUINTARA/24TH STREET',\n",
    "\n",
    "}\n",
    "\n",
    "route_stops_drop_routes_list = ['BAYVIEW HUNTERS POINT EXPRESS','CALIFORNIA EXPRESS','MARINA EXPRESS','BART EARLY BIRD','BAYSHORE A EXPRESS',\n",
    "                                'BAYSHORE B EXPRESS', 'SAN BRUNO OWL','3RD-19TH AVE OWL','INGLESIDE BUS','OWL TARAVAL',\n",
    "                                'JUDAH BUS','OWL JUDAH','THIRD BUS']\n",
    "\n",
    "\n",
    "muni[['route_number', 'route_long_name']] = muni['Route'].str.split(' ', n = 1, expand = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "101a3629",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_stops['route_long_name'] = route_stops['route_long_name'].replace(standardize_route_stops_long_name_dictionary)\n",
    "muni['route_long_name'] = muni['route_long_name'].replace(muni_route_long_name_dictionary)\n",
    "\n",
    "muni['route_number'] = muni['route_number'].replace(muni_route_number_dictionary)\n",
    "\n",
    "muni = muni[~muni['route_long_name'].isin(muni_drop_suspended_routes_list)]\n",
    "route_stops = route_stops[~route_stops['route_long_name'].isin(route_stops_drop_routes_list)]\n",
    "\n",
    "muni = muni[['Month', 'Average Daily Boardings', 'route_number', 'route_long_name']]\n",
    "route_stops = route_stops[['stop_id', 'stop_name', 'stop_lat', 'stop_lon', 'route_long_name']] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d154732",
   "metadata": {},
   "outputs": [],
   "source": [
    "## get geo dataframes for route_stops and bikeshare_station -> create a 400 meter buffer size for each bus stop -> \n",
    "# -> find which stations fall inside each buffer ->\n",
    "# -> drop duplicate stations that appear in each route -> join each route-month from muni with the stations near that route -> \n",
    "# -> keep only the stations that already exist by that Month -> count unique stations per route-month -> merge back into muni panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf69c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "stops_gdf = gpd.GeoDataFrame(route_stops, geometry = gpd.points_from_xy(route_stops['stop_lon'], route_stops['stop_lat'], crs = 'EPSG:4326').to_crs(epsg = 3857))\n",
    "stations_gdf = gpd.GeoDataFrame(bikeshare_stations, geometry = gpd.points_from_xy(bikeshare_stations['end_lng'], bikeshare_stations['end_lat']), crs = 'EPSG:4326').to_crs(epsg = 3857)\n",
    "\n",
    "stops_buffered = stops_gdf.copy()\n",
    "stops_buffered['geometry'] = stops_buffered.geometry.buffer(400)\n",
    "\n",
    "route_stop_station = gpd.sjoin(stations_gdf, stops_buffered, predicate = 'within', how = 'inner')\n",
    "\n",
    "route_station_pairs = route_stop_station[['route_long_name', 'end_station_id', 'first_appeared_at']].drop_duplicates() \n",
    "# THE STATIONS WITHIN 400 METERS OF AT LEAST ONE STOP ON EACH ROUTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0cf1c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "route_month = muni[['route_long_name', 'Month']].drop_duplicates()\n",
    "\n",
    "route_month_station = route_month.merge(route_station_pairs, on = 'route_long_name', how = 'left')\n",
    "\n",
    "mask_active = route_month_station['first_appeared_at'] <= route_month_station['Month']\n",
    "route_month_station = route_month_station[mask_active]\n",
    "\n",
    "route_month_station_counts = route_month_station.groupby(['route_long_name', 'Month'])['end_station_id'].nunique().reset_index(name = 'unique_stations_within_400m')\n",
    "\n",
    "muni_with_station_counts = muni.merge(route_month_station_counts, on = ['route_long_name', 'Month'], how = 'left').fillna({'unique_stations_within_400m': 0})\n",
    "\n",
    "muni_with_station_counts['treated'] = (muni_with_station_counts['unique_stations_within_400m'] > 0).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda11e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Is there enough routes that start with 0 stations within 400 meters and later gain stations within 400 meters (switchers)?\n",
    "# The coefficient estimate is found only by routes where treatment changes over time (the switchers). Routes that are always treated or never treated\n",
    "# do not contribute to the coefficient estimate\n",
    "\n",
    "df = muni_with_station_counts.copy()\n",
    "\n",
    "route_treatment_summary = (\n",
    "    df.groupby('route_number')['treated'].agg(['min','max','mean'])\n",
    "    .assign(\n",
    "        group = lambda d: np.select(\n",
    "            [(d['max'] == 0), \n",
    "             (d['min'] == 0) & (d['max'] == 1), \n",
    "             (d['min'] == 1)\n",
    "            ], \n",
    "            ['never_treated', 'switcher', 'always_treated'], \n",
    "            default = 'other'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "route_treatment_counts = route_treatment_summary['group'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b9efdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run regression on entire sample \n",
    "\n",
    "panel = df.copy()\n",
    "panel = panel.set_index(['route_number', 'Month'])\n",
    "\n",
    "panel['treated'] = (panel['unique_stations_within_400m'] > 0).astype(int)\n",
    "panel['log_boardings'] = np.log(panel['Average Daily Boardings'])\n",
    "\n",
    "model = PanelOLS(dependent = panel['log_boardings'], exog = panel[['treated']], entity_effects = True, time_effects = True)\n",
    "print(model.fit(cov_type = 'clustered', cluster_entity = True))\n",
    "\n",
    "# There's an x percent decline in (log) average daily boardings for routes that go from 0 stations to at least 1 station within 400 meters, controlling for \n",
    "# entity and time fixed effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9d33b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try a continuous treatment \n",
    "\n",
    "panel = df.copy()\n",
    "panel = panel.set_index(['route_number', 'Month'])\n",
    "\n",
    "panel['treated'] = (panel['unique_stations_within_400m'] > 0).astype(int)\n",
    "panel['log_boardings'] = np.log(panel['Average Daily Boardings'])\n",
    "\n",
    "model = PanelOLS(dependent = panel['log_boardings'], exog = panel[['unique_stations_within_400m']], entity_effects = True, time_effects = True)\n",
    "print(model.fit(cov_type = 'clustered', cluster_entity = True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a82bd19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I CAN'T LEARN MUCH ABOUT THE CAUSAL EFFECT FROM THIS SFMTA DATASET ALONE BECAUSE:\n",
    "# ALMOST ALL THE ROUTES ARE ALWAYS TREATED,\n",
    "# THERE ARE ALMOST NO ROUTES THAT SWITCH BETWEEN TREATED AND UNTREATED,\n",
    "# THERE'S LITTLE TO NO VARIATION IN THE NUMBER OF UNIQUE STATIONS WITHIN 400 METERS (unique_stations_within_400m) OVER TIME\n",
    "# in short, need more SFMTA data between 2010-2019"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
